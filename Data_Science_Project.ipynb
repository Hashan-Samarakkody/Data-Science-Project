{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Members \n",
    "#### IM/2021/007 - S.D.S.H. SAMARAKKODI\n",
    "#### IM/2021/035 - R.L.L.T. SAMPATH\n",
    "#### IM/2021/053 - N.W.I.M. PRASAN\n",
    "#### IM/2021/086 - T.M.S.P. DHANAPALA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: \n",
    "Extract the data from the given URL and save it in a CSV file. \n",
    "\n",
    "The data to be extracted includes the following fields,\n",
    "1. Name\n",
    "2. Designation\n",
    "3. Room\n",
    "4. Fax\n",
    "5. Phone\n",
    "6. Email\n",
    "7. Specialization(s)\n",
    "    \n",
    "The URL to scrape is: https://dim.kln.ac.lk/index.php/staff/academic-staff\n",
    "The data should be saved in a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach:\n",
    "\n",
    "1. Prompt the user to enter a filename to save the data.\n",
    "\n",
    "2. Check if a file with the same name already exists in the directory.\n",
    "\n",
    "3. If the file exists, ask the user if they want to overwrite the existing file.\n",
    "\n",
    "4. If the user chooses to overwrite, break the loop and proceed.\n",
    "\n",
    "5. If the user chooses not to overwrite, prompt the user for a new filename.\n",
    "\n",
    "6. If the file does not exist, proceed with scraping the data.\n",
    "\n",
    "7. Define the URL to scrape and send a GET request to the URL.\n",
    "\n",
    "8. Parse the HTML content using BeautifulSoup.\n",
    "\n",
    "9. Find all elements with class \"sppb-column-addons\" which contain the lecturer information.\n",
    "\n",
    "10. Extract the required fields (Name, Designation, Room, Fax, Phone, Email, Specialization(s)).\n",
    "\n",
    "11. Extract the specialization(s) from the individual lecturer pages.\n",
    "\n",
    "12. Save the extracted data in a CSV file with the provided filename.\n",
    "\n",
    "13. Handle any exceptions that occur during the scraping process and display an appropriate error message.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tAn error occurred while sending the request.\n",
      "\tPlease check your internet connection!!\n",
      "\n",
      "\tNo data was extracted!\n",
      "\tExiting the program.\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for web scraping and working with CSV files\n",
    "import requests as rs\n",
    "from bs4 import BeautifulSoup as Bs\n",
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "# Function to check if a specialization text is valid\n",
    "def is_valid_specialization(txt):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        txt (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # Convert text to string\n",
    "    txt = str(txt).strip()\n",
    "\n",
    "    # Define invalid strings to check for\n",
    "    invalid_strings = ['BSc', 'IEEE', ',', 'PhD', 'B.Sc',\n",
    "                       'Member', '.', ':', 'Ph D', '?', '2', ')', ' - ']\n",
    "    # Loop through invalid strings and check if they are present in the text\n",
    "    for string in invalid_strings:\n",
    "        if txt.__contains__(string):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "# Function to format designation string\n",
    "def format_designation(designation):\n",
    "    \"\"\"\n",
    "    Remove the parentheses from the designation string.\n",
    "\n",
    "    Parameters:\n",
    "    designation (str): The designation string to format.\n",
    "\n",
    "    Returns:\n",
    "    str: The formatted designation string.\n",
    "    \"\"\"\n",
    "    # Remove parentheses from the designation string\n",
    "    designation = designation.replace('(', '').replace(')', '')\n",
    "    return str(designation)\n",
    "\n",
    "\n",
    "# Prompt the user for the filename to save the data\n",
    "filename = input(\"Enter the filename to save the data (without extension): \")\n",
    "\n",
    "# Loop to check if a file with the same name already exists\n",
    "while True:\n",
    "    if os.path.exists(f\"{filename}.csv\"):\n",
    "        # Ask the user if they want to overwrite the existing file\n",
    "        overwrite = input(\n",
    "            f\"A file named '{filename}.csv' already exists. Do you want to overwrite it? (y/n): \")\n",
    "\n",
    "        if overwrite.lower() == 'y':\n",
    "            # Break the loop and overwrite the existing file\n",
    "            break\n",
    "        elif overwrite.lower() == 'n':\n",
    "            # Prompt the user for a new filename\n",
    "            filename = input(\n",
    "                \"Enter a new filename to save the data: \")\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'y' or 'n'.\")\n",
    "    else:\n",
    "        # Break the loop if the file does not exist\n",
    "        break\n",
    "\n",
    "# Define global variables\n",
    "page_links = []\n",
    "all_specializations = []\n",
    "lecturers_info_list = []\n",
    "\n",
    "# Define the URL to scrape\n",
    "url = \"https://dim.kln.ac.lk/index.php/staff/academic-staff\"\n",
    "\n",
    "try:\n",
    "    # Send a GET request to the URL\n",
    "    response = rs.get(url)\n",
    "    response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = Bs(response.content, 'html.parser')\n",
    "\n",
    "    # Find all staff divisions\n",
    "    staff_divs = soup.find_all('div', class_=\"clearfix\")\n",
    "\n",
    "    # Extract page links from staff divisions\n",
    "    for div in staff_divs:\n",
    "        links = div.find_all('a', href=True)\n",
    "        for link in links:\n",
    "            if \"https://science.kln.ac.lk/depts/im/index.php/\" in link['href']:\n",
    "                page_links.append(link['href'].strip())\n",
    "\n",
    "    # Extract specializations from each page link\n",
    "    for link in page_links:\n",
    "\n",
    "        response2 = rs.get(link)\n",
    "        response2.raise_for_status()\n",
    "\n",
    "        soup2 = Bs(response2.content, 'html.parser')\n",
    "        spans = soup2.find_all('span', class_=\"sppb-panel-title\")\n",
    "\n",
    "        for span in spans:\n",
    "            if \"Area\" in span.text:\n",
    "                div = span.find_next('div', class_=\"sppb-panel-collapse\")\n",
    "\n",
    "                for content in div:\n",
    "                    if content.text != None and is_valid_specialization(content.text):\n",
    "                        list_items = content.find_all('li')\n",
    "                        specializations = []\n",
    "\n",
    "                        for item in list_items:\n",
    "                            specializations.append(item.text.strip())\n",
    "\n",
    "                        all_specializations.append(specializations)\n",
    "\n",
    "    # Extract lecturer information\n",
    "    lecturers = soup.find_all(class_=\"sppb-column-addons\")\n",
    "\n",
    "    # Iterate over each lecturer element and extract the required information\n",
    "    for lecturer in lecturers:\n",
    "\n",
    "        # Extract lecturer's name\n",
    "        name_tag = lecturer.find('h3')\n",
    "        name = name_tag.text.strip() if name_tag else ''\n",
    "\n",
    "        # Extract lecturer's designation\n",
    "        designation_tag = lecturer.find('strong')\n",
    "        designation = format_designation(\n",
    "            designation_tag.text.strip()) if designation_tag else ''\n",
    "\n",
    "        # Extract lecturer's room\n",
    "        room_tag = lecturer.find('p', string=lambda x: x and 'Room' in x)\n",
    "        room = room_tag.text.strip().split(\n",
    "            \":\")[1].strip() if room_tag else ''\n",
    "\n",
    "        # Extract lecturer's fax number\n",
    "        fax_tag = lecturer.find('p', string=lambda x: x and 'Fax' in x)\n",
    "        fax = fax_tag.text.strip().split(\":\")[1].strip() if fax_tag else ''\n",
    "\n",
    "        # Extract lecturer's phone number\n",
    "        phone_tag = lecturer.find('p', string=lambda x: x and 'Phone' in x)\n",
    "        phone = phone_tag.text.strip().split(\n",
    "            \":\")[1].strip() if phone_tag else ''\n",
    "\n",
    "        # Extract lecturer's email(s)\n",
    "        email_tags = lecturer.find_all(\n",
    "            'a', href=lambda x: x and 'mailto:' in x)\n",
    "        emails = ', '.join([email.text.strip() for email in email_tags])\n",
    "\n",
    "        # Check if any information is available for the lecturer\n",
    "        if any([name, designation, room, fax, phone, emails]):\n",
    "            lecturers_info_list.append(\n",
    "                [name, designation, room, fax, phone, emails])\n",
    "\n",
    "except rs.RequestException as e:\n",
    "    # Check if the error is due to a connection issue\n",
    "    if isinstance(e, rs.ConnectionError):\n",
    "        print(\"\\n\\tAn error occurred while sending the request.\\n\\tPlease check your internet connection!!\\n\")\n",
    "    else:\n",
    "        print(\"\\n\\tUnable to send the request to the URL. Please try again later.\")\n",
    "\n",
    "\n",
    "# Check if the data was extracted successfully\n",
    "if not lecturers_info_list:\n",
    "    print(\"\\tNo data was extracted!\\n\\tExiting the program.\\n\")\n",
    "    exit()\n",
    "else:\n",
    "    # Write the data to a CSV file\n",
    "    try:\n",
    "        with open(f\"{filename}.csv\", 'w', newline='') as csv_file:\n",
    "\n",
    "            # Create a CSV writer object\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "\n",
    "            # Write the headers to the CSV file\n",
    "            csv_writer.writerow(\n",
    "                ['Name', 'Designation', 'Room', 'Fax', 'Phone', 'Email', 'Specialization(s)'])\n",
    "\n",
    "            total_rows = len(lecturers_info_list)\n",
    "\n",
    "            # Write lecturer information along with their specializations to the CSV file\n",
    "            for i in range(total_rows):\n",
    "                csv_writer.writerow(\n",
    "                    lecturers_info_list[i] + [', '.join(all_specializations[i])])\n",
    "\n",
    "        print(f\"Data has been successfully written to '{filename}.csv'.\")\n",
    "\n",
    "    except PermissionError as e:\n",
    "        print(\"\\n\\tThe file is already open in another program. \\n\\tPlease close it and try again!\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\tAn error occurred when writing the data to '{\n",
    "              filename}.csv'!\\n\")\n",
    "\n",
    "    finally:\n",
    "        # Close the CSV file\n",
    "        if 'csv_file' in locals():\n",
    "            csv_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
